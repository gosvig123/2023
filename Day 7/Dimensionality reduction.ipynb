{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f615f49e-edd2-4232-b4ee-99d9b85ed787",
   "metadata": {},
   "source": [
    "*Credits: Applied Data Analysis (ADA) course at EPFL (https://dlab.epfl.ch/teaching/fall2020/cs401/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34e232-7bd4-4921-9d5b-bab16b547bad",
   "metadata": {},
   "source": [
    "## Visualizing high dimensional data\n",
    "\n",
    "|*|continuous|categorical|\n",
    "|---|---|---|\n",
    "|**supervised**|regression|classification|\n",
    "|**unsupervised**|**dim. reduction**|clustering|\n",
    "\n",
    "Visualizing 2-dimensional data is easy, but what happens when we have more features? \n",
    "\n",
    "We can use dimensionality reduction techniques!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55686e62-762f-4487-bd00-980eea20578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8257c-b179-41f6-9095-3d329c49cb60",
   "metadata": {},
   "source": [
    "Let start by generating some artifical clusters with 3 features. \n",
    "We use the same number of samples and groups as the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809dac80-354b-4bfa-8e73-6c5a09499d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_centers = 3\n",
    "total_samples = 100\n",
    "\n",
    "# This create some artifical clusters with standard dev. = 1.5\n",
    "X3d, _ = make_blobs(n_samples=total_samples, \n",
    "                     centers=n_centers, \n",
    "                     cluster_std=1.5,\n",
    "                     n_features=3,\n",
    "                     random_state=1)\n",
    "\n",
    "print(\"The features of the first sample are: %s\" % X3d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b859c-dbb7-436b-9df1-2eb2c22fbaad",
   "metadata": {},
   "source": [
    "To transform this features vector in a form that can be represented in a simple plot, we can reduce the number of dimensions by preserving as much information as possible. Let's see two techniques that can help in this task:\n",
    "\n",
    "- [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html): tries to preserve the Global Structure of data. It is the most common dimensionality reduction technique.\n",
    "- [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html): tries to preserve the Local structure of data. It is specifically designed for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69f273-2c93-4cde-a32a-bf256553c9b2",
   "metadata": {},
   "source": [
    "### Visualize the 3d blobs\n",
    "\n",
    "In order to properly visualize the blob groups, let's declare a K-Means model with the same number of centroids and fit it to the original dataset. Use _random\\_state=0_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe7862-5640-4de7-9d52-e49ec765868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the data in 3 groups.\n",
    "kmeans = ...\n",
    "labels = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b90acf-70c5-49cb-909a-bb138dcad34f",
   "metadata": {},
   "source": [
    "Let's visualize the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eda22f-c4fb-4a96-9867-8c640d2a928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X3d[:,0], X3d[:,1], X3d[:,2], c=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83d74c-b30f-4a89-96ff-f576da8d36ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PCA\n",
    "\n",
    "Declare a PCA model with a 2-dimensional embedded space. For this, use `sklearn`'s built-in function `PCA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4f167-4505-4017-a15d-61a2dd3f3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cee45f-7d18-4857-958f-92455ffebc32",
   "metadata": {},
   "source": [
    "Fit the data and make the transformation into the lower dimensional space. For this, you can use the `.fit()` and `.transform()` implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ecab6a-bc83-4978-96cb-5f08a7ddf829",
   "metadata": {},
   "outputs": [],
   "source": [
    "... # fit the model\n",
    "X_reduced_pca = ...\n",
    "\n",
    "print(\"The features of the first sample are: %s\" % X_reduced_pca[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2898012-ae96-48e5-b28a-63f3a20b7aa6",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "\n",
    "Declare a t-SNE model with a 2-dimensional embedded space. For this, use `sklearn`'s built-in function `TSNE`. Use _random\\_state=0_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8bea4-d8bd-408e-98a7-766612439c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385bf903-113f-4d68-b066-96307404940f",
   "metadata": {},
   "source": [
    "Fit the data and make the transformation into the lower dimensional space. For this, you can use the `.fit_transform()` implementation, which performs both operations at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ac2bf-de43-49b2-afbb-1cde4434319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_tsne = ...\n",
    "\n",
    "print(\"The features of the first sample are: %s\" % X_reduced_tsne[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471c429-4924-4c61-94be-a35115a9c2ff",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "\n",
    "The features are reduced in both cases to a 2d space. Please note that they are not the same because the two techniques optimize different objectives.\n",
    "\n",
    "Let's plot the resulting embeddings to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a90424-6bcb-401d-9c85-444ff09a82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(13,6), sharey=True)\n",
    "\n",
    "# Plot the data reduced in 2d space with t-SNE\n",
    "axs[0].scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=labels, alpha=0.6)\n",
    "axs[0].set_title(\"t-SNE\")\n",
    "\n",
    "# Plot the data reduced in 2d space with PCA\n",
    "axs[1].scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=labels, alpha=0.6)\n",
    "axs[1].set_title(\"PCA\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd7484-c01a-451c-a7a0-e2126655a28a",
   "metadata": {},
   "source": [
    "We can see how both algorithms split the data into three clusters, which actually correspond to the very same clusters found by the K-Means model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82d44b-f0e0-4f1b-bf80-a6af134684cf",
   "metadata": {},
   "source": [
    "## Explained variance of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834f551-cd7a-4797-a758-667877be7145",
   "metadata": {},
   "source": [
    "As you know, PCA algorithm compresses the data to features so that the amount of explained variance retained is maximized. Let's have a look at how the number of components chosen affects the percentage of variance explained.\n",
    "\n",
    "First, declare and fit two different PCA models: with 2 and 3 number of components, respectively. Again, we leave you the documentation as a reference: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964f3c1-5248-4cbd-9631-5ec2c16d5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and fit PCA 2\n",
    "pca_2 = ...\n",
    "... # fit\n",
    "\n",
    "# Declare and fit PCA 3\n",
    "pca_3 = ...\n",
    "... # fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9743a6-5541-4cef-af47-2f24f831d5d5",
   "metadata": {},
   "source": [
    "Before moving on: what do you think the percentage of explained variance will be for the PCA model with 3 components?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b4e48-ad02-4fdb-b038-949c381f6481",
   "metadata": {},
   "source": [
    "`insert your thoughts here`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f84a4f-b417-422c-b064-cf112c199cde",
   "metadata": {},
   "source": [
    "Calculate the percentage of variance explained by each of the selected components. For this, you can use the attribute `explained_variance_ratio_`, check out the documentation for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df8e84-8c4a-47d9-b049-d1d0762629ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd102f1e-a686-401c-8c6a-4a8867cc72b8",
   "metadata": {},
   "source": [
    "Use numpy's function `.sum()` to obtain the total percentage of explained variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9142956-701b-48b3-b8be-59c952fe3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc7789-89c1-45e9-8b96-cbaac97d4fb1",
   "metadata": {},
   "source": [
    "Follow the same process for the PCA with 3 components. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3d2f3-0697-4cba-8a5e-dd1da39b99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
