{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97575ce4",
   "metadata": {},
   "source": [
    "*Credits: Applied Data Analysis (ADA) course at EPFL (https://dlab.epfl.ch/teaching/fall2020/cs401/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f29e4e",
   "metadata": {},
   "source": [
    "## Clustering with K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57010791",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn how to discover clusters in data using `Python` and `Scikit-learn`\n",
    "\n",
    "|*|continuous|categorical|\n",
    "|---|---|---|\n",
    "|**supervised**|regression|classification|\n",
    "|**unsupervised**|dim. reduction|**clustering**|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2be91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb4518",
   "metadata": {},
   "source": [
    "Let's start by creating some **[synthetic](https://en.wikipedia.org/wiki/Synthetic_data)** data!\n",
    "First, we create a super secret number that represents the number of the cluster to generate. \n",
    "\n",
    "Don't print it! We'll try to discover it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e46c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "top_secret_number = random.randint(2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a6974",
   "metadata": {},
   "source": [
    "Now we can generate some data distributed in _top\\_secret\\_number_ groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d57d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 100\n",
    "\n",
    "# This create some artifical clusters with standard dev. = 2\n",
    "X, _, centers = make_blobs(n_samples=total_samples, \n",
    "                           centers=top_secret_number, \n",
    "                           cluster_std=2,\n",
    "                           n_features=2,\n",
    "                           return_centers=True, \n",
    "                           random_state=42)\n",
    "\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382a799",
   "metadata": {},
   "source": [
    "Let's see how these clusters look like and where is their center:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b005d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], alpha=0.6)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Artificial clusters (%s samples)\" % total_samples)\n",
    "\n",
    "for c in centers:\n",
    "    plt.scatter(c[0], c[1], marker=\"+\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c519af",
   "metadata": {},
   "source": [
    "### Clustering the data\n",
    "How many clusters do you see? Probably easy for a human, but not so trivial for a computer. \n",
    "\n",
    "Let's try to group the data with K-Means. Recall that K-Means requires you to specify the number of clusters (K). Let's start by testing multiple values between 1 and 9.\n",
    "\n",
    "Fill in the required code to declare a K-Means model with `sklearn` and fit it to the data. For this, make use of the function `KMeans` and the already well-known `.fit()`. Please, choose a _random\\_state_ of 42. Check out the documentation for more info: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "**Remark:** the kmeans object attribute `labels_` is an array with the label values for each point. On the other hand `cluster_centers_` contains the coordinates of the centroids for each of the clusters. You can check out these attributes and more in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5bb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 1\n",
    "MAX_CLUSTERS = 9\n",
    "\n",
    "# Compute number of row and columns\n",
    "COLUMNS = 3\n",
    "ROWS = math.ceil((MAX_CLUSTERS-MIN_CLUSTERS)/COLUMNS)\n",
    "fig, axs = plt.subplots(ROWS, COLUMNS, figsize=(10,8), sharey=True, sharex=True)\n",
    "\n",
    "# Plot the clusters\n",
    "for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS+1):\n",
    "    current_column = (n_clusters-MIN_CLUSTERS)%COLUMNS\n",
    "    current_row = (n_clusters-MIN_CLUSTERS)//COLUMNS\n",
    "    # Get the axis where to add the plot\n",
    "    ax = axs[current_row, current_column]\n",
    "    \n",
    "    # Cluster the data with the current number of clusters\n",
    "    '''\n",
    "    FILL IN YOUR CODE HERE\n",
    "    '''\n",
    "    # Declare the K-Means model\n",
    "    kmeans = ...\n",
    "    # Train it\n",
    "    ...\n",
    "    \n",
    "    # Plot the data by using the labels as color\n",
    "    ax.scatter(X[:,0], X[:,1], c=kmeans.labels_, alpha=0.6)\n",
    "    ax.set_title(\"%s clusters\"%n_clusters)\n",
    "    ax.set_xlabel(\"Feature 1\")\n",
    "    ax.set_ylabel(\"Feature 2\")\n",
    "    # Plot the centroids\n",
    "    for c in kmeans.cluster_centers_:\n",
    "        ax.scatter(c[0], c[1], marker=\"+\", color=\"red\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eea146",
   "metadata": {},
   "source": [
    "### How to select K in K-Means?\n",
    "\n",
    "You have a couple of options:\n",
    "- Silhouette score: Find the K with the desired tradeoff between the number of clusters and cohesion/separation.\n",
    "- Elbow method: Find the \"elbow\" in the curve of the Sum of Squared Errors\n",
    "\n",
    "Let's see what we can observe using the Elbow method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47361fd",
   "metadata": {},
   "source": [
    "#### Elbow method\n",
    "\n",
    "The function below computes the SSE for different values of K, and plots its distribution. Complete ir by declaring a K-Means model for each value, training it using the training data, and extracting the SSE.\n",
    "\n",
    "*Hint:* the kmeans object has an attribute containing the Sum of Squared Errors. Check again the documentation (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) to find this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a52b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sse(features_X, start=1, end=9):\n",
    "    sse_array = []\n",
    "    for k in range(start, end):\n",
    "        '''\n",
    "        FILL IN YOUR CODE HERE\n",
    "        '''\n",
    "        # Declare the K-Means model. Choose random_state=10\n",
    "        kmeans = ...\n",
    "        # Train it\n",
    "        ...\n",
    "        # Extract the Sum of Squared Errors\n",
    "        sse = ...\n",
    "        \n",
    "        sse_array.append({\"k\": k, \"sse\": sse})\n",
    "\n",
    "    sse_array = pd.DataFrame(sse_array)\n",
    "    # Plot the data\n",
    "    plt.plot(sse_array.k, sse_array.sse)\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"Sum of Squared Errors\")\n",
    "    \n",
    "plot_sse(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fcf157",
   "metadata": {},
   "source": [
    "**Quiz**: Which would be the optimal number of clusters k given by the elbow method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0d62c-9423-4282-b1b3-8c316101a4ed",
   "metadata": {},
   "source": [
    "` Your answer here `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7c8ea-a33a-4c27-b8e3-cbde5b676e51",
   "metadata": {},
   "source": [
    "Let's plot the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8688a-b16b-4b05-b164-7ed75b3ebd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fac559",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(4,4), sharey=True)\n",
    "\n",
    "# Plot the clusters with optimal K\n",
    "labels = KMeans(n_clusters=optimal_k, random_state=0).fit_predict(X)\n",
    "axs.scatter(X[:,0], X[:,1], c=labels, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfecf92",
   "metadata": {},
   "source": [
    "Ultimately it is up to you (domain expert!) to pick the number of clusters that better represent the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
