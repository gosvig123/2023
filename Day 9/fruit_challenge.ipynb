{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport piplite\nawait piplite.install('seaborn')\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Fruit classification challenge!",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Data**:\n<br>\nWe provide a training dataset comprising 10’000 photoplethysmography (PPG) signals sampled\nat 10 Hz (30-second duration each). Each of these 10’000 PPG recordings has a label\n(fruit name) that can be used to train an ML model.\n\n**Goal**:<br>\nThe idea is to :\n1. Design an ML-based solution to classify these PPG signals into the different fruits and\ntrain it using the training dataset.\n2. Generate the outputs for the 10’000 recordings of the test dataset and upload the results in the shared drive by 12:30h.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Recall common steps to tackle a Machine Learning challenge:\n1. Exploratory Data Analysis\n    -  Check the type of data we have\n    -  Check data and label distribution\n    -  Visualizations (scatterplots, histograms, boxplots, ...)\n2. Feature selection:\n    - Assess which features to use from the data\n    - Iterative process, usually trial-error\n3. Model selection\n    - Try different models and evaluate them via train/validation split or k-fold cross validation\n    - Select best candidate or few best candidates\n4. Model evaluation\n    - Assess the performance of the best model on a test dataset/submit the results on the test dataset\n    ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's load the data, make sure to check you are correctly handling the headers of the datasets!",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data_raw = ...\nfruits_raw = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Exploratory data analysis (EDA)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First, let's convert the data to a 2D numpy array, and the fruits (labels) to a 1D numpy array.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data = ...\nfruits = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "To better visualize the distribution of our labels, let's make a bar plot with the total counts of each different fruit (label). **Hint**: you can use the [sns](https://seaborn.pydata.org/generated/seaborn.countplot.html) function from seaborn.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now let's see how the data signals look like, plot the first one!",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We can now visualize different examples for each of the different fruits",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# get all fruit names\nfruit_names = np.unique(fruits)\n\n# Plot some examples of time series for each of the fruits\nmax_n = 4\nfor idx in range(len(fruit_names)):\n    fig, ax = plt.subplots(1, max_n, figsize=(5*max_n, 5))\n    \n    # select one fruit type\n    fruit = fruit_names[idx] \n    \n    # Select, at random, 4 examples of that fruit\n    fruit_indices = np.where(np.array(fruits) == fruit)[0]\n    random.shuffle(fruit_indices)\n    fruit_indices = fruit_indices[0:max_n]\n    for n_fruit in range(len(fruit_indices)):\n        n = fruit_indices[n_fruit] \n        ax[n_fruit].plot(data[n])\n        ax[n_fruit].set_title(fruit)\n        \n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Finally, for each different fruit, let's print some statistics such as the average mean, std, min and max of the corresponding signals",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for fruit in fruit_names:\n    avg_mean = ...\n    avg_std = ...\n    avg_min = ...\n    avg_max = ...\n    \n    print(fruit)\n    print('Average mean %f, std %f, min %f max %f' % (avg_mean, avg_std, avg_min, avg_max))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Train-validation split ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First let's create the X (predictors) and y (targets or labels) for our problem. We will start with a minimal example, where X will be the mean value of each of the signals, and y just the name of the fruit. **Note**: X should be 2D.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = ...\ny = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "To be able to feed this data into a Machine Learning model later, we need y to be numerical (differente integer corresponding to each different category or fruit). Use the [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to do the transformation! ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's do the train/validation split with a validation share of 20%",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Model training",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Initialize and fit a LogisticRegression model, use a maximum number of iterations of 1000",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Make the predictions on the validation set, and report the accuracy (share of correctly classified fruits)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "predictions = ...\naccuracy = ...\nprint(\"Validation accuracy is %.2f\" % accuracy)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Submit your results on test set",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We first load the test data in the proper format",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_data_raw = pd.read_csv('quiz_test_data.csv',header=None)\ntest_data = data_raw.values.flatten()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We generate the X_test matrix, in this case with the only predictor we used, the mean of the signals. Not that for more complex models where more predictors share used, this should be updated accordingly.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_test = np.expand_dims(test_data.mean(axis=1),1)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Generate the predictions. Note the predictions will be integers. Transform them back to the corresponding fruit names for the final submission. **Hint**: check the [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) documentation.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_predictions = ...\ntest_fruit_predictions = ...",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now you are ready to generate the output .txt file and share it. You can upload the final solutions at the end of the day in the shared drive. The format should be 'results_name_surname.txt'.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "file_path = 'results_enzo_dubois.txt'\nnp.savetxt(file_path, test_fruit_predictions,fmt='%s')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Next steps, now is your turn!",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Some ideas that you can try to improve the results:\n- Use more statistic from the signals as features (std, min, max, skewness, quantiles, ...)\n- Try to exploit temporal information from the signals (is there a periodicity?), it might be useful to peak detection or fourier techniques to incorporate temporal information in our features...\n- Use other models that we have already seen (random forests, boosting algorithms, MLP, other deep learning models, ...?)\n- Model ensembling (merge predictions from different models to generate an \"ensembled\" prediction)\n- Check out external libraries designed for these kind of use cases such as [tsai](https://timeseriesai.github.io/tsai/) (more advanced)\n\n**Note:** If you don't have enough computing power for some solutions you can try the CPU/GPUs of [google collab](https://colab.research.google.com/?hl=es)\n\n    \n",
      "metadata": {}
    }
  ]
}