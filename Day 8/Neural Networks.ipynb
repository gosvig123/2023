{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca46d350-6aa7-4471-bc25-2319894d6d9c",
   "metadata": {},
   "source": [
    "# Using neural networks\n",
    "\n",
    "In this tutorial, we will use a classic neural network named Multilayer Perceptron, or MLP.\n",
    "\n",
    "This is a very generic network that consists of the composition of several single perceptrons, as shown in the image below. The input data flows forwardly throughout the different layers, until it reaches the output nodes. The learning is performed using the same Gradient Descent technique that we have seen during the course! (With a bit more complex formula, due to the composition of gradients).\n",
    "\n",
    "\n",
    "<img src=\"img/mlp.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a2064-07f7-4c0c-a897-281105774e8e",
   "metadata": {},
   "source": [
    "First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908d48e-a71a-4383-ab04-7817d3cde9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b18284-aefa-4535-acb6-4aaa21eed628",
   "metadata": {},
   "source": [
    "The aim of this guide is to build a classification model to detect diabetes. For this, we will be using [Kaggle's diabetes dataset](https://www.kaggle.com/datasets/mathchi/diabetes-data-set). \n",
    "\n",
    "Ps: Don't you know what Kaggle is? Ask your instructor!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbec73-3e53-4797-91c7-00cf106d0ba5",
   "metadata": {},
   "source": [
    "Load the dataset, contained in the `data/` folder, and print show the first 5 records. You can use function `read_csv` for this: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef653bf-be01-4b6f-91c5-fab93991fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbcf66-e8b7-499b-bd0f-3f729e17495d",
   "metadata": {},
   "source": [
    "How many observations and variables does the dataset contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b6fce-0494-405f-8364-e0732e2a6efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34bc90b-9e6e-467c-a118-05f164575a1e",
   "metadata": {},
   "source": [
    "The different variables for this dataset are described as follows:\n",
    "* Pregnancies - Number of times pregnant.\n",
    "* Glucose - Plasma glucose concentration.\n",
    "* BloodPressure - Diastolic blood pressure (mm Hg).\n",
    "* SkinThickness - Skinfold thickness (mm).\n",
    "* Insulin - Hour serum insulin (mu U/ml).\n",
    "* BMI – Basal metabolic rate (weight in kg/height in m).\n",
    "* DiabetesPedigreeFunction - Diabetes pedigree function.\n",
    "* Age - Age in years.\n",
    "* Outcome - “1” represents the presence of diabetes while “0” represents the absence of it. This is the variable we want to create a predictor on.\n",
    "\n",
    "Show some basic statistics for the dataset variables. You can use pandas' `describe()` for this purpose: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d3954-251c-4e58-8a8e-8a254ce60c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a074bea-4193-4723-8297-1b555f1e9d39",
   "metadata": {},
   "source": [
    "Looking at the summary for the 'Outcome' variable, we observe that the mean value is 0.35, which means that around 35 percent of the observations in the dataset have diabetes. Therefore, the baseline accuracy is 65 percent and our neural network model should definitely beat this baseline benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7111f3-3017-40fd-a1e5-2eefe0ff7801",
   "metadata": {},
   "source": [
    "Create 2 lists. One containing one element, the target variable name, and the other containing the other 8 predictor variables. We will use these lists to benefit from the pandas' slicing operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a66899-11f0-4de5-b506-5bc3dc8f578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ...\n",
    "predictors = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d75e6-b707-4582-924b-94d34d1de95d",
   "metadata": {},
   "source": [
    "Normalize the predictive variables to have a maximum value of 1 and a minimum value of 0. For this, you can do your own implementation, or use sklearn's `MinMaxScaler` function: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "Use again pandas' `describe` function to verify the correctness of your approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8abce7-2987-4b7c-a768-9c680dbfb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a559c6b-5548-49a3-84ee-24be16aaf93b",
   "metadata": {},
   "source": [
    "Slice the dataset into using the previously created indices, to craft your model's input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d1655-9080-4e06-96ea-fbfc00e2cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a4377-2bc8-429d-8a8d-a68b84e89863",
   "metadata": {},
   "source": [
    "Use sklearn's `train_test_split` to split your dataset into a train and a test cohort. The test size should comprise the 30% of the total size. Use a _random\\_state_ of 40: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689f86a-9aeb-4486-9a17-a1727a9fe9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd59000-d48a-477b-8d53-f879e1af4a8e",
   "metadata": {},
   "source": [
    "Print the size of both your training and testing to verify that the split was done properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e41871-f0eb-46ff-8ef2-7aa628229a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee3db2-2996-4e23-80aa-7746eec66e9e",
   "metadata": {},
   "source": [
    "Time to model our Multilayer Perceptron! For this, you can use sklearn's `MLPClassifier` function: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "You can use the reference documentation to set 3 hidden layers, each with a composed of 8 neurons, and the maximum number of iterations to 500.\n",
    "\n",
    "To train the model you can use the `fit()` function, as seen during the course.\n",
    "\n",
    "If you encounter a sklearn warning about lack of convergence, you can increase a bit the argument _max\\_iter_. But beware that you could run into an overfitting situation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456c8ae-9cd9-4511-a292-07d1a99d0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you encounter a sklearn warning that recommends you to use ravel(), you probably should write y_train.ravel()\n",
    "\n",
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21e950-d560-4c98-b869-023776898c52",
   "metadata": {},
   "source": [
    "Use the model's `predict()` function to obtain the predictions for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26bd30-83d2-4c88-89ce-d86ef2f1cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5366bd7-d21c-4027-b062-5ff2945a9998",
   "metadata": {},
   "source": [
    "Once the predictions are generated, we can evaluate the performance of the model. Being a classification algorithm, we would like to check the accuracy metrics. However, since the dataset is not completely balanced, the precision, recall, and f1 metrics are also very interesting to us.\n",
    "\n",
    "Let's use sklearn's `confusion_matrix` function to obtain the confusion matrix from the training predictions: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c7bf0-b60e-4778-84d3-200611d91750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ebc5d0-9e71-4830-966e-7f6ce4177e91",
   "metadata": {},
   "source": [
    "Sklearn also provides a function to conveniently verify the performance of our model. Use this function, `classification_report`, to see our performance: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e1ef6-6c4a-4ad6-a28b-eb4cf7cea7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a print statement for a better visualization\n",
    "\n",
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007f562-1ca3-43c6-aeb5-c875ee3af2e5",
   "metadata": {},
   "source": [
    "While results look promising, lets recall that all these are done on data already seen, as this is the data we have train with. Repeat the same process with the test predictions, and verify that the performance is still good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a6b24-99ae-4926-8375-7d1b67e8c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b920730-18c5-41a2-9b42-5be21274e8cb",
   "metadata": {},
   "source": [
    "We have also improved the baseline performance with unseen data. That is very good news!\n",
    "\n",
    "The model can be further improved by doing cross-validation, feature engineering, or changing the arguments in the neural network estimator. Try to iterate and beat these results!\n",
    "\n",
    "You can also compare your work with the notebooks provided in the [Kaggle's dataset code section](https://www.kaggle.com/datasets/mathchi/diabetes-data-set/code)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
