{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# The right price",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The aim of this notebook is to use a Multilayer Percerptron (MLP) architecture to predict the price of football players based on some data available about them. The right price (the labeled data for training) comes from transfermrkt.com from 2017. For more details about the dataset, check [here](https://github.com/Lakshaypahuja21/FOOTBALL-ENGLISH_PREMIER_LEAGUE)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Exploratory Data Analysis (EDA)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport piplite\nawait piplite.install('seaborn')\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import KFold",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "First things first! Let's load the data into memory using Pandas:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here\ndata_raw.head(5)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we will do some analysis. Which is the highest market value? Which players are worth this amount?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# add your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Do the same for the least valuable players:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# add your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now, lets select some variables. Create a dataframe containing only the variables **name, age, position, market_value, page_views, fpl_value, fpl_sel, region, big_club, new_signing**.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now, some names are too long. Rename: position for pos, market_value for value, page_views for views and new signing for signing.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The fpl_sel variable has the \"%\" sign on it and won't be interpreted by the algorithm. The following line handles with this:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data['fpl_sel'] = data['fpl_sel'].replace('%','',regex=True).astype('float')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now, for each position let's print the average value (fpl_value) of the players. Which positions are the most, and least valued?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's now generate a new column fpl_value_dist with the difference between the fpl_value of a player and the mean of the players in the same position",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data['fpl_value_dist'] = ...\ndata.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The new fpl_value_dist variable allows us to compare the fpl_value between different players in different positions in a \"fair\" way. Let's retrieve the top and least \"valuable\" players. To do so, sort the dataframe based on the value of fpl_value_dist and display the 5 upper rows and the 5 lower rows of the ordered dataset",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's do some statistical analysis: Print the pearson correlation matrix between all the numeric variables. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# data_numeric will contain the numeric variables:\ndata_numeric = data.select_dtypes(include = np.number)\ncorr = ...\nprint(corr)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we can visualize the correlation matrix using the [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) function from seaborn.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we will do a [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html) to see how the outcome variable (price) is distributed between postions.\n\nPositions naming:\n\n1. AM: attacking midfielder\n2. CF: center forward\n3. LW: left wing\n4. RW: right wing\n5. SS: second stricker \n6. RM: right midfielder\n7. LB: left back defender\n8. RB: right back defender\n9. CB: center back defender\n10. CM: center midfielder\n11. GK: goal keeper\n12. LM: left midfielder\n13. DM: defensive midfielder\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let's do the same visualization to compare players who are signing a new contract and those that are not.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We can also try to find relations between the price and the views or the price and the % of fpl selection. Create a [scatter](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) plot between this variables.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Notice the most viewed player is very cheap. Who is him? Print his name!",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Lastly to use a ML model with theis dataset we have to format the categorical variables and convert them into dummies. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data = pd.get_dummies(data, columns = ['pos', 'big_club', 'region', 'signing'])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Generate train - test split",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y = data['value']\nX = data.drop('value', axis = 1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We have to scale the data between 0 and 1. Do it without using any function from sklearn by applying the formula: \n\n$$ scaled variable = \\frac{variable-minimum}{maximum-minimum}$$",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# predictors are all variables except the name of the player\npredictors = X.columns\npredictors = predictors.drop('name')\n\n#store the values for later use:\nminimum = ...\nmaximum = ...\n\n#scale\nX[predictors] = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now let's make the train/test split by keeping 70% of the data as training data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "names_train = X_train['name']\nnames_test = X_test['name']\nX_train = X_train.drop('name', axis = 1)\nX_test = X_test.drop('name', axis = 1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Model selection",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Create two different models and try k-fold (with k = 5) cross validation to choose the best one. The first model should have only one hidden layer with 20 neurons and the second one 2 hidden layers with 10 neurons each. Both models should have max_iter=8000. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Create the first model",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mlp1 = ...",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Create the second one",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mlp2 = ...",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we will use k-fold crossvalidation to select the best model. Before that, we need to transform the dataframes into numpy arrays",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train_arr = np.array(X_train)\nX_test_arr = np.array(X_test)\ny_train_arr = np.array(y_train)\ny_test_arr = np.array(y_test)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Complete the code below to perform [k-fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) crossvalidation. We want to store the MSE in each iteration in the corresponding error list:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "kf = KFold(n_splits=5, shuffle = True, random_state = 33)\n\nkf_error1 = []\nkf_error2 = []\n\nfor train_index, test_index in kf.split(X_train_arr):\n\n    X_train_kf, X_test_kf = ...\n    y_train_kf, y_test_kf = ...\n    \n    mlp1.fit(X_train_kf, y_train_kf)\n    mlp2.fit(X_train_kf, y_train_kf)\n    \n    predictions1 = ...\n    predictions2 = ...\n    \n    mse1 = ...\n    mse2 = ...\n\n    errorA.append(mse1)\n    errorB.append(mse2)\n    ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Print the average cross-validation errors for the two models, which model had the best overall performance?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code here",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Model evaluation",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now, let's retrain the best model configuration it using the full training data available",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mlp_best = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# fit the model with the whole training data\n...",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Predict the values for the testing dataset. Compute the Mean Squared Error and the Mean Absolute Error.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "predictions = ...\n\nMSE = ...\nMAE = ...\n\nprint(MSE)\nprint(MAE)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we can create an imaginary player by deciding arbitrary values for the variables. Check how the predicted price changed as you modify the different variables!",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data.loc[100]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Generate the variables for the player\nnew_player = ...\n\n# Standardize the variables\nnew_player = (new_player-minimum)/(maximum-minimum)\n\n# Predict the price\nprice = ...",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}